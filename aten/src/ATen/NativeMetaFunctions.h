#pragma once

// @generated by torchgen/gen.py from NativeMetaFunctions.h

#include <ATen/core/Tensor.h>
#include <ATen/core/IListRef.h>
#include <ATen/TensorMeta.h>
#include <ATen/TensorIterator.h>



namespace at {

namespace meta {

struct structured_sgn : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_acos : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_add_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other, const at::Scalar & alpha);
};
struct structured_addmv : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & mat, const at::Tensor & vec, const at::Scalar & beta, const at::Scalar & alpha);
};
struct structured_all_dim : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, bool keepdim);
};
struct structured_all_dims : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::OptionalIntArrayRef dim, bool keepdim);
};
struct structured_any_dim : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, bool keepdim);
};
struct structured_any_dims : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::OptionalIntArrayRef dim, bool keepdim);
};
struct structured_argmax : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, c10::optional<int64_t> dim, bool keepdim);
};
struct structured_argmin : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, c10::optional<int64_t> dim, bool keepdim);
};
struct structured_acosh : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_asinh : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_atanh : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_asin : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_atan : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_baddbmm : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & batch1, const at::Tensor & batch2, const at::Scalar & beta, const at::Scalar & alpha);
};
struct structured_bitwise_not : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_copysign_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_bmm : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & mat2);
};
struct structured_cat : public at::impl::MetaBase {
    
                template <bool DIM = false, bool VALID = false, bool ALL_CONTIGUOUS = false, bool ALL_SAME_DTYPE = false, bool ALL_SAME_SIZES_AND_STRIDE = false, bool MEMORY_FORMAT = false>
                struct precompute_out {
                    
                    precompute_out<true, VALID, ALL_CONTIGUOUS, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> set_dim(int64_t value) {
                        static_assert(DIM == false, "dim already set");
                        precompute_out<true, VALID, ALL_CONTIGUOUS, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> ret;
ret.dim = value;
ret.valid = this->valid;
ret.all_contiguous = this->all_contiguous;
ret.all_same_dtype = this->all_same_dtype;
ret.all_same_sizes_and_stride = this->all_same_sizes_and_stride;
ret.memory_format = this->memory_format;
return ret;
                    }
                

                    precompute_out<DIM, true, ALL_CONTIGUOUS, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> set_valid(int64_t value) {
                        static_assert(VALID == false, "valid already set");
                        precompute_out<DIM, true, ALL_CONTIGUOUS, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> ret;
ret.dim = this->dim;
ret.valid = value;
ret.all_contiguous = this->all_contiguous;
ret.all_same_dtype = this->all_same_dtype;
ret.all_same_sizes_and_stride = this->all_same_sizes_and_stride;
ret.memory_format = this->memory_format;
return ret;
                    }
                

                    precompute_out<DIM, VALID, true, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> set_all_contiguous(bool value) {
                        static_assert(ALL_CONTIGUOUS == false, "all_contiguous already set");
                        precompute_out<DIM, VALID, true, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> ret;
ret.dim = this->dim;
ret.valid = this->valid;
ret.all_contiguous = value;
ret.all_same_dtype = this->all_same_dtype;
ret.all_same_sizes_and_stride = this->all_same_sizes_and_stride;
ret.memory_format = this->memory_format;
return ret;
                    }
                

                    precompute_out<DIM, VALID, ALL_CONTIGUOUS, true, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> set_all_same_dtype(bool value) {
                        static_assert(ALL_SAME_DTYPE == false, "all_same_dtype already set");
                        precompute_out<DIM, VALID, ALL_CONTIGUOUS, true, ALL_SAME_SIZES_AND_STRIDE, MEMORY_FORMAT> ret;
ret.dim = this->dim;
ret.valid = this->valid;
ret.all_contiguous = this->all_contiguous;
ret.all_same_dtype = value;
ret.all_same_sizes_and_stride = this->all_same_sizes_and_stride;
ret.memory_format = this->memory_format;
return ret;
                    }
                

                    precompute_out<DIM, VALID, ALL_CONTIGUOUS, ALL_SAME_DTYPE, true, MEMORY_FORMAT> set_all_same_sizes_and_stride(bool value) {
                        static_assert(ALL_SAME_SIZES_AND_STRIDE == false, "all_same_sizes_and_stride already set");
                        precompute_out<DIM, VALID, ALL_CONTIGUOUS, ALL_SAME_DTYPE, true, MEMORY_FORMAT> ret;
ret.dim = this->dim;
ret.valid = this->valid;
ret.all_contiguous = this->all_contiguous;
ret.all_same_dtype = this->all_same_dtype;
ret.all_same_sizes_and_stride = value;
ret.memory_format = this->memory_format;
return ret;
                    }
                

                    precompute_out<DIM, VALID, ALL_CONTIGUOUS, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, true> set_memory_format(at::MemoryFormat value) {
                        static_assert(MEMORY_FORMAT == false, "memory_format already set");
                        precompute_out<DIM, VALID, ALL_CONTIGUOUS, ALL_SAME_DTYPE, ALL_SAME_SIZES_AND_STRIDE, true> ret;
ret.dim = this->dim;
ret.valid = this->valid;
ret.all_contiguous = this->all_contiguous;
ret.all_same_dtype = this->all_same_dtype;
ret.all_same_sizes_and_stride = this->all_same_sizes_and_stride;
ret.memory_format = value;
return ret;
                    }
                
                    int64_t dim;
int64_t valid;
bool all_contiguous;
bool all_same_dtype;
bool all_same_sizes_and_stride;
at::MemoryFormat memory_format;
            };
    using meta_return_ty = precompute_out <true, true, true, true, true, true>;
    meta_return_ty meta(const at::ITensorListRef & tensors, int64_t dim);
};
struct structured_ceil : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_clamp : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, at::OptionalScalarRef min, at::OptionalScalarRef max);
};
struct structured_clamp_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, at::OptionalTensorRef min, at::OptionalTensorRef max);
};
struct structured_clamp_max : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & max);
};
struct structured_clamp_max_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & max);
};
struct structured_clamp_min : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & min);
};
struct structured_clamp_min_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & min);
};
struct structured_cos : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_cosh : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_cumprod : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, c10::optional<at::ScalarType> dtype);
};
struct structured_cumsum : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, c10::optional<at::ScalarType> dtype);
};
struct structured_div_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_div_Tensor_mode : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other, c10::optional<c10::string_view> rounding_mode);
};
struct structured_erf : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_erfc : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_exp : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_exp2 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_expm1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_floor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_frac : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_gcd : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_lcm : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_index_Tensor : public TensorIteratorBase {
    
                template <bool SIZES = false, bool STRIDES = false>
                struct precompute_out {
                    
                    precompute_out<true, STRIDES> set_sizes(at::DimVector value) {
                        static_assert(SIZES == false, "sizes already set");
                        precompute_out<true, STRIDES> ret;
ret.sizes = value;
ret.strides = this->strides;
return ret;
                    }
                

                    precompute_out<SIZES, true> set_strides(at::DimVector value) {
                        static_assert(STRIDES == false, "strides already set");
                        precompute_out<SIZES, true> ret;
ret.sizes = this->sizes;
ret.strides = value;
return ret;
                    }
                
                    at::DimVector sizes;
at::DimVector strides;
            };
    using meta_return_ty = precompute_out <true, true>;
    meta_return_ty meta(const at::Tensor & self, at::IOptTensorListRef indices);
};
struct structured_index_copy : public at::impl::MetaBase {
    
                template <bool DIM = false>
                struct precompute_out {
                    
                    precompute_out<true> set_dim(int64_t value) {
                        static_assert(DIM == false, "dim already set");
                        precompute_out<true> ret;
ret.dim = value;
return ret;
                    }
                
                    int64_t dim;
            };
    using meta_return_ty = precompute_out <true>;
    meta_return_ty meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source);
};
struct structured_isin_Tensor_Tensor : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & elements, const at::Tensor & test_elements, bool assume_unique, bool invert);
};
struct structured_isin_Tensor_Scalar : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & elements, const at::Scalar & test_element, bool assume_unique, bool invert);
};
struct structured_isin_Scalar_Tensor : public at::impl::MetaBase {
    
    
    void meta(const at::Scalar & element, const at::Tensor & test_elements, bool assume_unique, bool invert);
};
struct structured_log : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_log10 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_log1p : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_log2 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_logaddexp : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_logaddexp2 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_xlogy_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured__log_softmax : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, bool half_to_float);
};
struct structured__log_softmax_backward_data : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & output, int64_t dim, at::ScalarType input_dtype);
};
struct structured_aminmax : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, c10::optional<int64_t> dim, bool keepdim);
};
struct structured_max_dim : public at::impl::MetaBase {
    
                template <bool DIM = false>
                struct precompute_out {
                    
                    precompute_out<true> set_dim(int64_t value) {
                        static_assert(DIM == false, "dim already set");
                        precompute_out<true> ret;
ret.dim = value;
return ret;
                    }
                
                    int64_t dim;
            };
    using meta_return_ty = precompute_out <true>;
    meta_return_ty meta(const at::Tensor & self, int64_t dim, bool keepdim);
};
struct structured_amax : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef dim, bool keepdim);
};
struct structured_mean_dim : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::OptionalIntArrayRef dim, bool keepdim, c10::optional<at::ScalarType> dtype);
};
struct structured_min_dim : public at::impl::MetaBase {
    
                template <bool DIM = false>
                struct precompute_out {
                    
                    precompute_out<true> set_dim(int64_t value) {
                        static_assert(DIM == false, "dim already set");
                        precompute_out<true> ret;
ret.dim = value;
return ret;
                    }
                
                    int64_t dim;
            };
    using meta_return_ty = precompute_out <true>;
    meta_return_ty meta(const at::Tensor & self, int64_t dim, bool keepdim);
};
struct structured_amin : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef dim, bool keepdim);
};
struct structured_mm : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & mat2);
};
struct structured_mul_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_reciprocal : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_neg : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_round : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_round_decimals : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, int64_t decimals);
};
struct structured_gelu : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, c10::string_view approximate);
};
struct structured_gelu_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, c10::string_view approximate);
};
struct structured_hardshrink : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & lambd);
};
struct structured_hardshrink_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_out, const at::Tensor & self, const at::Scalar & lambd);
};
struct structured_rsqrt : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_silu : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_silu_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self);
};
struct structured_mish : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_sigmoid : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_sin : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_sinc : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_sinh : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured__softmax : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, bool half_to_float);
};
struct structured__softmax_backward_data : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & output, int64_t dim, at::ScalarType input_dtype);
};
struct structured_sum_dim_IntList : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::OptionalIntArrayRef dim, bool keepdim, c10::optional<at::ScalarType> dtype);
};
struct structured_sqrt : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_prod_dim_int : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, bool keepdim, c10::optional<at::ScalarType> dtype);
};
struct structured_tan : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_tanh : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_threshold : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & threshold, const at::Scalar & value);
};
struct structured_threshold_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Scalar & threshold);
};
struct structured_trunc : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_norm_ScalarOpt_dim_dtype : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::OptionalScalarRef p, at::IntArrayRef dim, bool keepdim, at::ScalarType dtype);
};
struct structured_norm_ScalarOpt_dim : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::OptionalScalarRef p, at::IntArrayRef dim, bool keepdim);
};
struct structured_sub_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other, const at::Scalar & alpha);
};
struct structured_heaviside : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & values);
};
struct structured_addmm : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & mat1, const at::Tensor & mat2, const at::Scalar & beta, const at::Scalar & alpha);
};
struct structured__addmm_activation : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & mat1, const at::Tensor & mat2, const at::Scalar & beta, const at::Scalar & alpha, bool use_gelu);
};
struct structured_index_add : public at::impl::MetaBase {
    
                template <bool DIM = false>
                struct precompute_out {
                    
                    precompute_out<true> set_dim(int64_t value) {
                        static_assert(DIM == false, "dim already set");
                        precompute_out<true> ret;
ret.dim = value;
return ret;
                    }
                
                    int64_t dim;
            };
    using meta_return_ty = precompute_out <true>;
    meta_return_ty meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, const at::Scalar & alpha);
};
struct structured_index_reduce : public at::impl::MetaBase {
    
                template <bool DIM = false>
                struct precompute_out {
                    
                    precompute_out<true> set_dim(int64_t value) {
                        static_assert(DIM == false, "dim already set");
                        precompute_out<true> ret;
ret.dim = value;
return ret;
                    }
                
                    int64_t dim;
            };
    using meta_return_ty = precompute_out <true>;
    meta_return_ty meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & source, c10::string_view reduce, bool include_self);
};
struct structured_scatter_src : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & src);
};
struct structured_scatter_value : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Scalar & value);
};
struct structured_scatter_reduce : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & src, c10::string_view reduce);
};
struct structured_scatter_value_reduce : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Scalar & value, c10::string_view reduce);
};
struct structured_scatter_add : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & src);
};
struct structured_scatter_reduce_two : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, const at::Tensor & src, c10::string_view reduce, bool include_self);
};
struct structured_eq_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & other);
};
struct structured_eq_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_bitwise_and_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_bitwise_or_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_bitwise_xor_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_bitwise_left_shift_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_bitwise_right_shift_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_tril : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t diagonal);
};
struct structured_triu : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t diagonal);
};
struct structured_digamma : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_lerp_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & end, const at::Scalar & weight);
};
struct structured_lerp_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & end, const at::Tensor & weight);
};
struct structured_ne_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & other);
};
struct structured_ne_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_ge_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & other);
};
struct structured_ge_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_le_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & other);
};
struct structured_le_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_gt_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & other);
};
struct structured_gt_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_lt_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & other);
};
struct structured_lt_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_gather : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t dim, const at::Tensor & index, bool sparse_grad);
};
struct structured_addcmul : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & tensor1, const at::Tensor & tensor2, const at::Scalar & value);
};
struct structured_addcdiv : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & tensor1, const at::Tensor & tensor2, const at::Scalar & value);
};
struct structured_triangular_solve : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & A, bool upper, bool transpose, bool unitriangular);
};
struct structured_lu_unpack : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & LU_data, const at::Tensor & LU_pivots, bool unpack_data, bool unpack_pivots);
};
struct structured_lgamma : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_polygamma : public TensorIteratorBase {
    
    
    void meta(int64_t n, const at::Tensor & self);
};
struct structured_erfinv : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_i0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_sign : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_signbit : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_atan2 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_fmod_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_hypot : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_igamma : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_igammac : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_nextafter : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_remainder_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_fmin : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_fmax : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_maximum : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_minimum : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_sort_stable : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, c10::optional<bool> stable, int64_t dim, bool descending);
};
struct structured_topk : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t k, int64_t dim, bool largest, bool sorted);
};
struct structured_all : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_any : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_renorm : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & p, int64_t dim, const at::Scalar & maxnorm);
};
struct structured_pow_Tensor_Tensor : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & exponent);
};
struct structured_pow_Scalar : public at::impl::MetaBase {
    
    
    void meta(const at::Scalar & self, const at::Tensor & exponent);
};
struct structured_pow_Tensor_Scalar : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & exponent);
};
struct structured__convert_indices_from_coo_to_csr : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, int64_t size, bool out_int32);
};
struct structured__convert_indices_from_csr_to_coo : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & crow_indices, const at::Tensor & col_indices, bool out_int32, bool transpose);
};
struct structured_mse_loss : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & target, int64_t reduction);
};
struct structured_nll_loss_forward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & target, at::OptionalTensorRef weight, int64_t reduction, int64_t ignore_index);
};
struct structured_nll_loss_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & target, at::OptionalTensorRef weight, int64_t reduction, int64_t ignore_index, const at::Tensor & total_weight);
};
struct structured_smooth_l1_loss : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & target, int64_t reduction, double beta);
};
struct structured_elu : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & alpha, const at::Scalar & scale, const at::Scalar & input_scale);
};
struct structured_elu_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Scalar & alpha, const at::Scalar & scale, const at::Scalar & input_scale, bool is_result, const at::Tensor & self_or_result);
};
struct structured_glu : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, int64_t dim);
};
struct structured_hardsigmoid : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_hardsigmoid_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self);
};
struct structured_leaky_relu : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & negative_slope);
};
struct structured_leaky_relu_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Scalar & negative_slope, bool self_is_result);
};
struct structured_softplus : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & beta, const at::Scalar & threshold);
};
struct structured_softplus_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Scalar & beta, const at::Scalar & threshold);
};
struct structured_softshrink : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & lambd);
};
struct structured_softshrink_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Scalar & lambd);
};
struct structured_adaptive_max_pool2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef output_size);
};
struct structured_adaptive_max_pool2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & indices);
};
struct structured_adaptive_max_pool3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef output_size);
};
struct structured_adaptive_max_pool3d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, const at::Tensor & indices);
};
struct structured_avg_pool2d : public at::impl::MetaBase {
    
                template <bool KH = false, bool KW = false, bool DH = false, bool DW = false, bool PADH = false, bool PADW = false>
                struct precompute_out {
                    
                    precompute_out<true, KW, DH, DW, PADH, PADW> set_kH(int64_t value) {
                        static_assert(KH == false, "kH already set");
                        precompute_out<true, KW, DH, DW, PADH, PADW> ret;
ret.kH = value;
ret.kW = this->kW;
ret.dH = this->dH;
ret.dW = this->dW;
ret.padH = this->padH;
ret.padW = this->padW;
return ret;
                    }
                

                    precompute_out<KH, true, DH, DW, PADH, PADW> set_kW(int64_t value) {
                        static_assert(KW == false, "kW already set");
                        precompute_out<KH, true, DH, DW, PADH, PADW> ret;
ret.kH = this->kH;
ret.kW = value;
ret.dH = this->dH;
ret.dW = this->dW;
ret.padH = this->padH;
ret.padW = this->padW;
return ret;
                    }
                

                    precompute_out<KH, KW, true, DW, PADH, PADW> set_dH(int64_t value) {
                        static_assert(DH == false, "dH already set");
                        precompute_out<KH, KW, true, DW, PADH, PADW> ret;
ret.kH = this->kH;
ret.kW = this->kW;
ret.dH = value;
ret.dW = this->dW;
ret.padH = this->padH;
ret.padW = this->padW;
return ret;
                    }
                

                    precompute_out<KH, KW, DH, true, PADH, PADW> set_dW(int64_t value) {
                        static_assert(DW == false, "dW already set");
                        precompute_out<KH, KW, DH, true, PADH, PADW> ret;
ret.kH = this->kH;
ret.kW = this->kW;
ret.dH = this->dH;
ret.dW = value;
ret.padH = this->padH;
ret.padW = this->padW;
return ret;
                    }
                

                    precompute_out<KH, KW, DH, DW, true, PADW> set_padH(int64_t value) {
                        static_assert(PADH == false, "padH already set");
                        precompute_out<KH, KW, DH, DW, true, PADW> ret;
ret.kH = this->kH;
ret.kW = this->kW;
ret.dH = this->dH;
ret.dW = this->dW;
ret.padH = value;
ret.padW = this->padW;
return ret;
                    }
                

                    precompute_out<KH, KW, DH, DW, PADH, true> set_padW(int64_t value) {
                        static_assert(PADW == false, "padW already set");
                        precompute_out<KH, KW, DH, DW, PADH, true> ret;
ret.kH = this->kH;
ret.kW = this->kW;
ret.dH = this->dH;
ret.dW = this->dW;
ret.padH = this->padH;
ret.padW = value;
return ret;
                    }
                
                    int64_t kH;
int64_t kW;
int64_t dH;
int64_t dW;
int64_t padH;
int64_t padW;
            };
    using meta_return_ty = precompute_out <true, true, true, true, true, true>;
    meta_return_ty meta(const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override);
};
struct structured_avg_pool2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override);
};
struct structured_avg_pool3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override);
};
struct structured_avg_pool3d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override);
};
struct structured_fractional_max_pool2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef output_size, const at::Tensor & random_samples);
};
struct structured_fractional_max_pool2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef output_size, const at::Tensor & indices);
};
struct structured_fractional_max_pool3d : public at::impl::MetaBase {
    
                template <bool POOLSIZET = false, bool POOLSIZEH = false, bool POOLSIZEW = false, bool OUTPUTT = false, bool OUTPUTH = false, bool OUTPUTW = false, bool NUMBATCH = false, bool NUMPLANES = false, bool INPUTT = false, bool INPUTH = false, bool INPUTW = false>
                struct precompute_out {
                    
                    precompute_out<true, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> set_poolSizeT(int64_t value) {
                        static_assert(POOLSIZET == false, "poolSizeT already set");
                        precompute_out<true, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = value;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, true, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> set_poolSizeH(int64_t value) {
                        static_assert(POOLSIZEH == false, "poolSizeH already set");
                        precompute_out<POOLSIZET, true, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = value;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, true, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> set_poolSizeW(int64_t value) {
                        static_assert(POOLSIZEW == false, "poolSizeW already set");
                        precompute_out<POOLSIZET, POOLSIZEH, true, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = value;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, true, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> set_outputT(int64_t value) {
                        static_assert(OUTPUTT == false, "outputT already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, true, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = value;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, true, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> set_outputH(int64_t value) {
                        static_assert(OUTPUTH == false, "outputH already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, true, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = value;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, true, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> set_outputW(int64_t value) {
                        static_assert(OUTPUTW == false, "outputW already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, true, NUMBATCH, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = value;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, true, NUMPLANES, INPUTT, INPUTH, INPUTW> set_numBatch(int64_t value) {
                        static_assert(NUMBATCH == false, "numBatch already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, true, NUMPLANES, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = value;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, true, INPUTT, INPUTH, INPUTW> set_numPlanes(int64_t value) {
                        static_assert(NUMPLANES == false, "numPlanes already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, true, INPUTT, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = value;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, true, INPUTH, INPUTW> set_inputT(int64_t value) {
                        static_assert(INPUTT == false, "inputT already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, true, INPUTH, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = value;
ret.inputH = this->inputH;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, true, INPUTW> set_inputH(int64_t value) {
                        static_assert(INPUTH == false, "inputH already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, true, INPUTW> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = value;
ret.inputW = this->inputW;
return ret;
                    }
                

                    precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, true> set_inputW(int64_t value) {
                        static_assert(INPUTW == false, "inputW already set");
                        precompute_out<POOLSIZET, POOLSIZEH, POOLSIZEW, OUTPUTT, OUTPUTH, OUTPUTW, NUMBATCH, NUMPLANES, INPUTT, INPUTH, true> ret;
ret.poolSizeT = this->poolSizeT;
ret.poolSizeH = this->poolSizeH;
ret.poolSizeW = this->poolSizeW;
ret.outputT = this->outputT;
ret.outputH = this->outputH;
ret.outputW = this->outputW;
ret.numBatch = this->numBatch;
ret.numPlanes = this->numPlanes;
ret.inputT = this->inputT;
ret.inputH = this->inputH;
ret.inputW = value;
return ret;
                    }
                
                    int64_t poolSizeT;
int64_t poolSizeH;
int64_t poolSizeW;
int64_t outputT;
int64_t outputH;
int64_t outputW;
int64_t numBatch;
int64_t numPlanes;
int64_t inputT;
int64_t inputH;
int64_t inputW;
            };
    using meta_return_ty = precompute_out <true, true, true, true, true, true, true, true, true, true, true>;
    meta_return_ty meta(const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef output_size, const at::Tensor & random_samples);
};
struct structured_max_pool2d_with_indices : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, bool ceil_mode);
};
struct structured_max_pool2d_with_indices_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::IntArrayRef kernel_size, at::IntArrayRef stride, at::IntArrayRef padding, at::IntArrayRef dilation, bool ceil_mode, const at::Tensor & indices);
};
struct structured_reflection_pad1d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_reflection_pad1d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_reflection_pad3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_reflection_pad3d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_replication_pad1d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_replication_pad1d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_replication_pad2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_replication_pad3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> padding);
};
struct structured_upsample_linear1d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, bool align_corners, c10::optional<double> scales);
};
struct structured_upsample_linear1d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, bool align_corners, c10::optional<double> scales);
};
struct structured_upsample_bilinear2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_bilinear2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_bilinear2d_aa : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_bilinear2d_aa_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_bicubic2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_bicubic2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_bicubic2d_aa : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_bicubic2d_aa_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_trilinear3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, bool align_corners, c10::optional<double> scales_d, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_trilinear3d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, bool align_corners, c10::optional<double> scales_d, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_nearest1d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, c10::optional<double> scales);
};
struct structured__upsample_nearest_exact1d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, c10::optional<double> scales);
};
struct structured_upsample_nearest1d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, c10::optional<double> scales);
};
struct structured__upsample_nearest_exact1d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, c10::optional<double> scales);
};
struct structured_upsample_nearest2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_nearest_exact2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_nearest2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_nearest_exact2d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_nearest3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, c10::optional<double> scales_d, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_nearest_exact3d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, at::ArrayRef<int64_t> output_size, c10::optional<double> scales_d, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_upsample_nearest3d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, c10::optional<double> scales_d, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured__upsample_nearest_exact3d_backward : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & grad_output, at::ArrayRef<int64_t> output_size, at::ArrayRef<int64_t> input_size, c10::optional<double> scales_d, c10::optional<double> scales_h, c10::optional<double> scales_w);
};
struct structured_sigmoid_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & output);
};
struct structured_logit_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & self, c10::optional<double> eps);
};
struct structured_tanh_backward : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & grad_output, const at::Tensor & output);
};
struct structured_slow_conv_transpose2d : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & weight, at::ArrayRef<int64_t> kernel_size, at::OptionalTensorRef bias, at::ArrayRef<int64_t> stride, at::ArrayRef<int64_t> padding, at::ArrayRef<int64_t> output_padding, at::ArrayRef<int64_t> dilation);
};
struct structured_isposinf : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_isneginf : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_entr : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_ndtri : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_log_ndtr : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_erfcx : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_xlog1py : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_special_zeta : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other);
};
struct structured_special_i0e : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_i1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_i1e : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_linalg_cholesky_ex : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, bool upper, bool check_errors);
};
struct structured_linalg_cross : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Tensor & other, int64_t dim);
};
struct structured_linalg_lu_factor_ex : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, bool pivot, bool check_errors);
};
struct structured_linalg_lu : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, bool pivot);
};
struct structured_linalg_lu_solve : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & LU, const at::Tensor & pivots, const at::Tensor & B, bool left, bool adjoint);
};
struct structured__linalg_det : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A);
};
struct structured_linalg_ldl_factor_ex : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, bool hermitian, bool check_errors);
};
struct structured_linalg_ldl_solve : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & LD, const at::Tensor & pivots, const at::Tensor & B, bool hermitian);
};
struct structured__linalg_slogdet : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A);
};
struct structured__linalg_eigh : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, c10::string_view UPLO, bool compute_v);
};
struct structured_linalg_inv_ex : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, bool check_errors);
};
struct structured_linalg_vector_norm : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & self, const at::Scalar & ord, at::OptionalIntArrayRef dim, bool keepdim, c10::optional<at::ScalarType> dtype);
};
struct structured__linalg_svd : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, bool full_matrices, bool compute_uv, c10::optional<c10::string_view> driver);
};
struct structured__linalg_solve_ex : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, const at::Tensor & B, bool left, bool check_errors);
};
struct structured_linalg_qr : public at::impl::MetaBase {
    
    
    void meta(const at::Tensor & A, c10::string_view mode);
};
struct structured_special_airy_ai : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x);
};
struct structured_special_bessel_j0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_bessel_j1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_bessel_y0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_bessel_y1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_chebyshev_polynomial_t : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_chebyshev_polynomial_u : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_chebyshev_polynomial_v : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_chebyshev_polynomial_w : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_hermite_polynomial_h : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_hermite_polynomial_he : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_laguerre_polynomial_l : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_legendre_polynomial_p : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_modified_bessel_i0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_modified_bessel_i1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_modified_bessel_k0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_modified_bessel_k1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & self);
};
struct structured_special_scaled_modified_bessel_k0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x);
};
struct structured_special_scaled_modified_bessel_k1 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x);
};
struct structured_special_shifted_chebyshev_polynomial_t : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_shifted_chebyshev_polynomial_u : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_shifted_chebyshev_polynomial_v : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_shifted_chebyshev_polynomial_w : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x, const at::Tensor & n);
};
struct structured_special_spherical_bessel_j0 : public TensorIteratorBase {
    
    
    void meta(const at::Tensor & x);
};

} // namespace meta
} // namespace at
